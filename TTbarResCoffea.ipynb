{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffea` Notebook to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "This module must be run twice: \n",
    "   1. Make the mistag rate in the \"anti-tag and probe\" selection \n",
    "and the expectation in the signal region from MC,\n",
    "   1. Applies that mistag rate and the mod-mass procedure to the single-tag selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity ($|y| \\le 1.0$, $|y| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 1100$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|y| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrootdstr = 'root://cmseos.fnal.gov//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcdfilename = 'flatqcd.txt'\n",
    "with open(qcdfilename) as f:\n",
    "    qcdfiles = [xrootdstr + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttbarfilename = 'TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8.txt'\n",
    "with open(ttbarfilename) as f:\n",
    "    ttbarfiles = [xrootdstr + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "client = Client('coffea-dask.fnal.gov:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, htCut=1100., minMSD=110., maxMSD=250., tau32Cut=0.7, ak8PtMin=400., bdisc=0.7,\n",
    "                writePredDist=True,isData=True,year=2019):\n",
    "        \n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        \n",
    "        self.btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "        self.ycats = ['cen', 'fwd']          # Central and forward\n",
    "        self.ttagcats = [\"0t\", \"1t\", \"2t\"]   # 0, 1, or both jets t tagged\n",
    "        # Combine categories like \"0bcen\", \"0bfwd\", etc:\n",
    "        self.anacats = [ b+y+t for b,y,t in itertools.product( self.btagcats, self.ycats, self.ttagcats) ]\n",
    "        self.anacats += ['pretag']\n",
    "        print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "        \n",
    "        ht_axis = hist.Bin(\"h_ak4ht\", r\"AK4 Jet H_{T} [GeV]\", 50, 0, 5000)\n",
    "        jetmass_axis = hist.Bin(\"jetmass\", r\"Jet $m$ [GeV]\", 50, 0, 500)\n",
    "        jetpt_axis = hist.Bin(\"jetpt\", r\"Jet $p_{T}$ [GeV]\", 50, 0, 5000)\n",
    "        jeteta_axis = hist.Bin(\"jeteta\", r\"Jet $\\eta$\", 50, -3, 3)\n",
    "        jetphi_axis = hist.Bin(\"jetphi\", r\"Jet $\\phi$\", 50, -6.28, 6.28)\n",
    "        jetsoftdrop_axis = hist.Bin(\"jetsoftdrop\", r\"Jet $m_{SD}$ [GeV]\", 50, 0, 5000)\n",
    "        jetn3b1_axis = hist.Bin(\"n3b1\", r\"Jet N3\", 50, 0, 1)\n",
    "        ttbarmass_axis = hist.Bin(\"ttbarmass\", r\"$m_{t\\bar{t}}$ [GeV]\", 50, 0, 5000)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'h_ak4ht'  : hist.Hist(\"Counts\", dataset_axis, cats_axis, ht_axis),\n",
    "            'ttbarmass': hist.Hist(\"Counts\", dataset_axis, cats_axis, ttbarmass_axis),\n",
    "            'jetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'jetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'jeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jeteta_axis),\n",
    "            'jetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jetphi_axis),\n",
    "            'jetsoftdrop': hist.Hist(\"Counts\", dataset_axis, cats_axis, jetsoftdrop_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "    \n",
    "    \"\"\"Define a function that 'tags' the ttbar candidate jets; Applied to every pair of jet candidates\"\"\"\n",
    "    def TAT(self, jetcand, tagger_switch): # Ttagger and Anti Tagger\n",
    "        tau32 = np.where(jetcand.tau2>0,jetcand.tau3/jetcand.tau2, 0 )\n",
    "        passTau32 = tau32 < self.tau32Cut\n",
    "        AntiPassTau32 = tau32 > self.tau32Cut\n",
    "        #passSoftDrop = jetcand.msoftdrop != None & self.minMSD < jetcand.msoftdrop < self.maxMSD\n",
    "        passSoftDrop = np.logical_and(self.minMSD < jetcand.msoftdrop, jetcand.msoftdrop < self.maxMSD)\n",
    "        ttag = passTau32 & passSoftDrop\n",
    "        antitag = AntiPassTau32 & passSoftDrop\n",
    "        if tagger_switch == 0:\n",
    "            return ttag\n",
    "        elif tagger_switch == 1:\n",
    "            return antitag\n",
    "            \n",
    "\n",
    "    def process(self, df):\n",
    "        \n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        \n",
    "        #dataset = events.metadata['dataset']\n",
    "        dataset = df['dataset']\n",
    "        FatJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'],\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            msoftdrop=df['FatJet_msoftdrop'],\n",
    "            jetId=df['FatJet_jetId'],\n",
    "            tau1=df['FatJet_tau1'],\n",
    "            tau2=df['FatJet_tau2'],\n",
    "            tau3=df['FatJet_tau3'],\n",
    "            tau4=df['FatJet_tau4'],\n",
    "            n3b1=df['FatJet_n3b1'],\n",
    "            btagDeepB=df['FatJet_btagDeepB']\n",
    "            )\n",
    "        \n",
    "        #weight = JaggedArray.fromcounts(\n",
    "        #    np.ones_like(df['Generator_binvar'],dtype=int),\n",
    "        #    df['Generator_weight']\n",
    "        #)\n",
    "        evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        output['cutflow']['all events'] += FatJets.size\n",
    "\n",
    "        twoFatJets = (FatJets.counts >= 2)\n",
    "        FatJets = FatJets[twoFatJets]\n",
    "        output['cutflow']['two FatJets'] += twoFatJets.sum()\n",
    "        \n",
    "        jet_id = (FatJets.jetId > 0)\n",
    "        \n",
    "        #print(\"jet_id[:,0]\", jet_id[:,0])          \n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += jet_id.any().sum()\n",
    "        \n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (np.abs(FatJets.eta) < 2.5)\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        output['cutflow']['jet kin'] += jetkincut_index.any().sum()\n",
    "        \n",
    "        evtweights = evtweights[twoFatJets]\n",
    "        ttbarcands = FatJets[:,0:2].distincts()\n",
    "\n",
    "        oneTTbar = (ttbarcands.counts >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += oneTTbar.sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "\n",
    "        \n",
    "        dPhiCut = (ttbarcands.i0.p4.delta_phi(ttbarcands.i1.p4) > 2.1).flatten()\n",
    "        output['cutflow']['dPhi > 2.1'] += dPhiCut.sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut]        \n",
    "        ttbarmass = ttbarcands.p4.sum().mass.flatten()\n",
    "        # Now get the analysis categories. \n",
    "        # They are (central, forward) cross (0b,1b,>=2b) cross (0t, 1t, 2t) \n",
    "        \n",
    "        \"\"\"Define center region and forward region possibilities\"\"\"\n",
    "        cen = np.abs(ttbarcands.i0.p4.y - ttbarcands.i1.p4.y) < 1.0\n",
    "        fwd = np.logical_not(cen)\n",
    "        \n",
    "        \"\"\"Define the btag requirement for individual jet candidates (Used to identify b-tagged jets)\"\"\" \n",
    "        btag_i0 = (ttbarcands.i0.btagDeepB > 0.7)\n",
    "        btag_i1 = (ttbarcands.i1.btagDeepB > 0.7)\n",
    "        \n",
    "        \"\"\"Randomly select one of the two subjets from the ttbar candidates\"\"\"\n",
    "        rand_cand = random.choice([ttbarcands.i0, ttbarcands.i1]) # Get jet pt of this for plots\n",
    "        other_cand = np.logical_not(rand_cand)\n",
    "            \n",
    "        \"\"\"Define the tagger switches for TAT function (for easy reading)\"\"\"\n",
    "        ttagger = 0\n",
    "        antitagger = 1\n",
    "        \n",
    "        \"\"\"Define the ttag requirement for random individual jet candidate (Used to identify t-tagged jets)\"\"\"\n",
    "        ttag_first = self.TAT(rand_cand, ttagger) # 1st randomly selected jet goes through t tagger \n",
    "        ttag_second = self.TAT(other_cand, ttagger) # 2nd jet goes through t tagger\n",
    "        anti_ttag_first = self.TAT(rand_cand, antitagger) \n",
    "        anti_ttag_second = self.TAT(other_cand, antitagger) # Get jet pt\n",
    "        \n",
    "        \"\"\"Keep track of 'fake' ttbar events and exclude them from ttbar candidates\"\"\"\n",
    "        # antitag_first with tag_second and vice-versa...\n",
    "        condition1 = np.logical_and(ttag_first, anti_ttag_second)\n",
    "        condition2 = np.logical_and(anti_ttag_first, ttag_second)\n",
    "        fake_ttbar = np.logical_or(condition1, condition2)\n",
    "        true_ttbar = np.logical_not(fake_ttbar)\n",
    "        ttbarcands = ttbarcands[true_ttbar]\n",
    "        \n",
    "        \"\"\"Define tagger possibilities for b's and t's (0b,1b,2b, 0t,1t,2t)\"\"\"\n",
    "        btag0 = np.logical_not(btag_i0) & np.logical_not(btag_i1)\n",
    "        btag1 = btag_i0 ^ btag_i1\n",
    "        btag2 = btag_i0 & btag_i1\n",
    "        \n",
    "        ttag0 = np.logical_not(ttag_first) & np.logical_not(ttag_second)\n",
    "        ttag1 = np.logical_or(ttag_first, ttag_second)\n",
    "        ttag2 = np.logical_and(ttag_first, ttag_second)\n",
    "        \n",
    "        # (cen & btag0 & antitag)\n",
    "        # (cen & btag1 & antitag)...\n",
    "        \"\"\"List all of the possible categories\"\"\"\n",
    "        cat000 = (cen & btag0 & ttag0).flatten()\n",
    "        cat001 = (cen & btag0 & ttag1).flatten()\n",
    "        cat002 = (cen & btag0 & ttag2).flatten()\n",
    "        \n",
    "        cat010 = (cen & btag1 & ttag0).flatten()\n",
    "        cat011 = (cen & btag1 & ttag1).flatten()\n",
    "        cat012 = (cen & btag1 & ttag2).flatten()\n",
    "        \n",
    "        cat020 = (cen & btag2 & ttag0).flatten()\n",
    "        cat021 = (cen & btag2 & ttag1).flatten()\n",
    "        cat022 = (cen & btag2 & ttag2).flatten()\n",
    "        \n",
    "        cat100 = (fwd & btag0 & ttag0).flatten()\n",
    "        cat101 = (fwd & btag0 & ttag1).flatten()\n",
    "        cat102 = (fwd & btag0 & ttag2).flatten()\n",
    "        \n",
    "        cat110 = (fwd & btag1 & ttag0).flatten()\n",
    "        cat111 = (fwd & btag1 & ttag1).flatten()\n",
    "        cat112 = (fwd & btag1 & ttag2).flatten()\n",
    "        \n",
    "        cat120 = (fwd & btag2 & ttag0).flatten()\n",
    "        cat121 = (fwd & btag2 & ttag1).flatten()\n",
    "        cat122 = (fwd & btag2 & ttag2).flatten()\n",
    "        \n",
    "        pretag = [True] * len(cen)\n",
    "\n",
    "        cats = [cat000,cat001,cat002,\n",
    "                cat010,cat011,cat012,\n",
    "                cat020,cat021,cat022,\n",
    "                cat100,cat101,cat102,\n",
    "                cat110,cat111,cat112,\n",
    "                cat120,cat121,cat122,pretag]\n",
    "    \n",
    "        labels_and_categories = dict(zip( self.anacats, cats ))\n",
    "        ttbarmass = ttbarcands.p4.sum().mass.flatten()\n",
    "        \n",
    "        for ilabel,icat in labels_and_categories.items():\n",
    "            output['cutflow'][ilabel] += np.sum(icat)\n",
    "            output['ttbarmass'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                ttbarmass=ttbarmass[icat],\n",
    "                                weight=evtweights[icat].flatten())\n",
    "            output['jetpt'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetpt=jetpt[icat],\n",
    "                                weight=evtweights[icat].flatten())\n",
    "            output['jeteta'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jeteta=jeteta[icat],\n",
    "                                weight=evtweights[icat].flatten())\n",
    "            output['jetphi'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetphi=jetphi[icat],\n",
    "                                weight=evtweights[icat].flatten())\n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "fileset = {\n",
    "    'TTbar':ttbarfiles,\n",
    "    #'QCD':qcdfiles # QCD_Pt-15to7000_TuneCP5_Flat_13TeV_pythia8\n",
    "    #'ZZ to 4mu': [\n",
    "    #    'data/ZZTo4mu.root'\n",
    "    #]\n",
    "}\n",
    "\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTbarResProcessor(),\n",
    "                                  #executor=processor.dask_executor,\n",
    "                                  executor=processor.iterative_executor,\n",
    "                                  executor_args={\n",
    "                                      'client': client, \n",
    "                                      'nano':False, \n",
    "                                      'flatten':True, \n",
    "                                      'workers': 4},\n",
    "                                  chunksize=50000, maxchunks=1\n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_fill_opts = {'alpha': 0.8, 'edgecolor':(0,0,0,.5)}\n",
    "stack_error_opts = {'label':'Stat. Unc.', 'hatch':'///', 'facecolor':'none', 'edgecolor':(0,0,0,.5), 'linewidth': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = hist.plotgrid(output['ttbarmass'], row=\"anacat\", overlay=\"dataset\", stack=False\n",
    "                                  #fill_opts=stack_fill_opts,\n",
    "                                  #error_opts=stack_error_opts,\n",
    "                                 )\n",
    "plt.yscale(\"log\")\n",
    "for iax in ax.flatten():\n",
    "    iax.autoscale(axis='y')\n",
    "#    plt.savefig('/uscms_data/d1/acwillia/singularity/TestPlot_' + '' + '.png')\n",
    "#plt.savefig('/uscms_data/d1/acwillia/singularity/TTagTestPlots.png')\n",
    "#plt.savefig('/uscms_data/d1/acwillia/TTagTestPlots_backup.png')\n",
    "    \n",
    "#bx = hist.plot1d(ttag_numerator)\n",
    "#for ibx in bx.flatten():\n",
    "#    ibx.autoscale(axis='y')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Events/s:\", output['cutflow']['all events']/elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in output['cutflow'].items():\n",
    "    print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mapping = {\n",
    "#    'QCD': ['QCD'],\n",
    "#}\n",
    "#output['ttbarmass'].group(\"dataset\", hist.Cat(\"dataset\", \"dataset\"), mapping)\n",
    "#hist_noDS = output['ttbarmass_pretag'].integrate('dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
